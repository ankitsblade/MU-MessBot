{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f5345c-7aa6-42d4-b059-41f580fd7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting numpy>=1.23 (from matplotlib)\n",
      "  Downloading numpy-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m178.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:02\u001b[0mm eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m196.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m193.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m183.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m174.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hUsing cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 numpy-2.2.2 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d71f3c8-6e14-49ac-9d7a-8094f2f53b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: anyio in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.2)\n",
      "Requirement already satisfied: certifi in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ankit/anaconda3/envs/rag_test/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Downloading ollama-0.4.6-py3-none-any.whl (13 kB)\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, annotated-types, pydantic, ollama\n",
      "Successfully installed annotated-types-0.7.0 ollama-0.4.6 pydantic-2.10.5 pydantic-core-2.27.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47a70ad-b5a8-45fc-b6a0-5b1ac67d5ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 82 entries\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open('Weekly Menu from 27-11-2023 to 03-12-2023.csv','r') as file:\n",
    "    dataset = file.readlines()\n",
    "    print(f\"loaded {len(dataset)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77099eb3-d756-48e0-b326-02c8db0b8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'\n",
    "\n",
    "VECTOR_DB = []\n",
    "\n",
    "def add_chunk_to_database(chunk):\n",
    "    embedding = ollama.embed(model=EMBEDDING_MODEL,input=chunk)['embeddings'][0]\n",
    "    VECTOR_DB.append((chunk,embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cc8cb85-fde4-41a0-9651-092d3547be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chunk 1/7 to the database\n",
      "Added chunk 2/7 to the database\n",
      "Added chunk 3/7 to the database\n",
      "Added chunk 4/7 to the database\n",
      "Added chunk 5/7 to the database\n",
      "Added chunk 6/7 to the database\n",
      "Added chunk 7/7 to the database\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 13\n",
    "for i in range(0, len(dataset), chunk_size):\n",
    "    chunk = dataset[i:i+chunk_size]  # Group 13 lines together\n",
    "    add_chunk_to_database(chunk)\n",
    "    print(f'Added chunk {i//chunk_size + 1}/{-(-len(dataset) // chunk_size)} to the database')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2896a2d8-f1cf-40a6-9280-1c7778bef0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a,b):\n",
    "  dot_product = sum([x * y for x, y in zip(a, b)])\n",
    "  norm_a = sum([x ** 2 for x in a]) ** 0.5\n",
    "  norm_b = sum([x ** 2 for x in b]) ** 0.5\n",
    "  return dot_product / (norm_a * norm_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7465d0c9-2c0c-466e-a0f8-ae695556a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "  query_embedding = ollama.embed(model=EMBEDDING_MODEL, input=query)['embeddings'][0]\n",
    "  # temporary list to store (chunk, similarity) pairs\n",
    "  similarities = []\n",
    "  for chunk, embedding in VECTOR_DB:\n",
    "    similarity = cosine_similarity(query_embedding, embedding)\n",
    "    similarities.append((chunk, similarity))\n",
    "  # sort by similarity in descending order, because higher similarity means more relevant chunks\n",
    "  similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "  # finally, return the top N most relevant chunks\n",
    "  return similarities[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "733d75e7-c6eb-4095-95b8-d047aec8ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask me a question:  Whats for lunch on wednesday\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved knowledge:\n",
      " - (similarity: 0.78) Tuesday,VELLIYAPAM,POORI,VEG MANCHOW SOUP,KOSLOW SANDWICH\n",
      "\n",
      " - (similarity: 0.78) Tuesday,VELLIYAPAM,POORI,VEG MANCHOW SOUP,KOSLOW SANDWICH\n",
      "\n",
      " - (similarity: 0.70) Wednesday,MYSORE BONDA,ONIONS,PULKA,SAMOSA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generation Phase\n",
    "input_query = input('Ask me a question: ')\n",
    "retrieved_knowledge = retrieve(input_query)\n",
    "\n",
    "print('Retrieved knowledge:')\n",
    "for chunk, similarity in retrieved_knowledge:\n",
    "  print(f' - (similarity: {similarity:.2f}) {chunk}')\n",
    "\n",
    "instruction_prompt = f'''You are a helpful chatbot.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{'\\n'.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d36e2589-b1be-41e5-a00f-269b4f126b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "Since it's Wednesday and the context is:\n",
      "\n",
      "Wednesday,MYSORE BONDA,ONIONS,PULKA,SAMOSA\n",
      "\n",
      "We can conclude that there will be lunch consisting of Mysore Bonda, onions, pulka ( possibly referring to a specific type of fried rice or snack), and Samosa."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model = LANGUAGE_MODEL,\n",
    "    messages =[\n",
    "        {'role':'system','content':instruction_prompt},\n",
    "        {'role':'user','content':input_query},\n",
    "    ],\n",
    "    stream = True,\n",
    ")\n",
    "\n",
    "print('Chatbot response:')\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'],end='',flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
